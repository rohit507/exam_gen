const local_index = {"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"index.html#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"index.html#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"index.html#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"getting-started.html","text":"","title":"Getting Started"},{"location":"misc-notes.html","text":"Notes \u00b6 This is just a scratchpad for notes taken during the development process. All the stuff here should be eventually moved somewhere else in these docs. Development / Infrastructure \u00b6 We're using pipenv to do environment and dependency management for this project. Installing pipenv took running sudo apt install pipenv on Ubuntu. Other install options are found here . Open shell in project directory with pipenv shell Install a package with pipenv install <pip-package> Run a command with pipenv run <command> Note: If you're inside a pipenv shell you can drop the pipenv run prefix from all of the commands here that have them. We're using mkdocs for documentation. We're using mkdocstrings to include generated docstrings in the mkdocs output. Look at this page for more detailed usage directions. The theme is mkdocs-material . Run doc server with pipenv run mkdocs serve and open http://127.0.0.1:8000/ . Build a static stite with pipenv run mkdocs build , results will be placed in the site/ directory. Using best practices taken from https://sourcery.ai/blog/python-best-practices/ : Import Sort: pipenv run isort PEP 8 Convention Check: pipenv run flake8 Static Type Check: pipenv run mypy Tests and Coverage: pipenv run pytest --cov --cov-fail-under=100 We're using the instructions here to setup setuptools and the core python packaging infrastucture. Useful Python Facts \u00b6 inspect.getargspec can get you get all sorts of information about the arguments of a function that's passed to it. Including: Arity, param names, keyword args, defaults, and more. This will be super useful for ensuring that there's consistency of parameters and a coherent argument structure for init and other user interface functions as we mixin a bunch of different classes. We should be able to use the __init_subclass_ mechanism to implement the sort of auto-collating settings system that I would like. Especially given how nice it would be have the sort of auto-documenting structure that I want. Take the following example class Bar(): bars = [] def __init_subclass__(cls, **kwargs): super().__init_subclass__(**kwargs) cls.bars = cls.bars + [cls.bar] class Foo(Bar): bar = \"A\" class Buzz(Foo): bar = \"B\" class Bing(Foo): bar = \"C\" print(Foo.bars) print(Buzz.bars) print(Bing.bars) With output: ['A'] ['A','B'] ['A','C'] Instead of accumulating a set of strings like in the above example, you could gather up information on the settings that were previously available. Plus the __init_subclass__ function gives you a nice place to both generate and set the doc string for an object (via __doc__ ). Honestly part of me is wondering whether I should use this mechanism for a lot of feature accumulation and overloading mechanisms in the library, rather than just for settings management. It's trivially simple and super powerful. It's just a monoid that we can sum down the inheritance heirarchy. Oh wait, I just tried adding this: class Bloop(Buzz,Bing): bar = \"D\" print(Bloop.bars) And got : ['A','B','D'] Which means that the system can't really handle multiple inheritance as is. I'm better off using some other introspection to go through parent classes and using some other hook for class init to set things up. Yup, that's it. We use __bases__ as the structure to get the parent classes and __init_subclass__ as the init hook. Things To Do \u00b6 TODO: Figure out what the options.install_requires actually means. TODO: Remove unneccesary dependencies from Pipfile.lock . TODO: Actually-set-up/Verify that the git pre-commit hook works. TODO: Move the notes from above somewhere appropriate within the docs or the code","title":"Miscellaneous Notes"},{"location":"misc-notes.html#notes","text":"This is just a scratchpad for notes taken during the development process. All the stuff here should be eventually moved somewhere else in these docs.","title":"Notes"},{"location":"misc-notes.html#development-infrastructure","text":"We're using pipenv to do environment and dependency management for this project. Installing pipenv took running sudo apt install pipenv on Ubuntu. Other install options are found here . Open shell in project directory with pipenv shell Install a package with pipenv install <pip-package> Run a command with pipenv run <command> Note: If you're inside a pipenv shell you can drop the pipenv run prefix from all of the commands here that have them. We're using mkdocs for documentation. We're using mkdocstrings to include generated docstrings in the mkdocs output. Look at this page for more detailed usage directions. The theme is mkdocs-material . Run doc server with pipenv run mkdocs serve and open http://127.0.0.1:8000/ . Build a static stite with pipenv run mkdocs build , results will be placed in the site/ directory. Using best practices taken from https://sourcery.ai/blog/python-best-practices/ : Import Sort: pipenv run isort PEP 8 Convention Check: pipenv run flake8 Static Type Check: pipenv run mypy Tests and Coverage: pipenv run pytest --cov --cov-fail-under=100 We're using the instructions here to setup setuptools and the core python packaging infrastucture.","title":"Development / Infrastructure"},{"location":"misc-notes.html#useful-python-facts","text":"inspect.getargspec can get you get all sorts of information about the arguments of a function that's passed to it. Including: Arity, param names, keyword args, defaults, and more. This will be super useful for ensuring that there's consistency of parameters and a coherent argument structure for init and other user interface functions as we mixin a bunch of different classes. We should be able to use the __init_subclass_ mechanism to implement the sort of auto-collating settings system that I would like. Especially given how nice it would be have the sort of auto-documenting structure that I want. Take the following example class Bar(): bars = [] def __init_subclass__(cls, **kwargs): super().__init_subclass__(**kwargs) cls.bars = cls.bars + [cls.bar] class Foo(Bar): bar = \"A\" class Buzz(Foo): bar = \"B\" class Bing(Foo): bar = \"C\" print(Foo.bars) print(Buzz.bars) print(Bing.bars) With output: ['A'] ['A','B'] ['A','C'] Instead of accumulating a set of strings like in the above example, you could gather up information on the settings that were previously available. Plus the __init_subclass__ function gives you a nice place to both generate and set the doc string for an object (via __doc__ ). Honestly part of me is wondering whether I should use this mechanism for a lot of feature accumulation and overloading mechanisms in the library, rather than just for settings management. It's trivially simple and super powerful. It's just a monoid that we can sum down the inheritance heirarchy. Oh wait, I just tried adding this: class Bloop(Buzz,Bing): bar = \"D\" print(Bloop.bars) And got : ['A','B','D'] Which means that the system can't really handle multiple inheritance as is. I'm better off using some other introspection to go through parent classes and using some other hook for class init to set things up. Yup, that's it. We use __bases__ as the structure to get the parent classes and __init_subclass__ as the init hook.","title":"Useful Python Facts"},{"location":"misc-notes.html#things-to-do","text":"TODO: Figure out what the options.install_requires actually means. TODO: Remove unneccesary dependencies from Pipfile.lock . TODO: Actually-set-up/Verify that the git pre-commit hook works. TODO: Move the notes from above somewhere appropriate within the docs or the code","title":"Things To Do"},{"location":"api/mixins/prepare_attrs.html","text":"PrepareAttrs Metaclass \u00b6 This metaclass makes it easier to control and manipulate the variables available during the class definition process, and has a lot of utility in making class-based EDSLs more elegant. Python already has the __init_subclass__ and __dict__ mechanisms for working with declaration statements in a class definition. These are great, but they're only capable of handling the environment of a class after a user has interacted with it. PrepareAttrs gives EDSL authors a way to prepare that environment beforehand and get a lot of additional power. Warning Only the final section has a full example. The other sections of this page use working but flawed examples to build up necessary information needed to understand the full function of the final example. Generated Documentation \u00b6 PrepareAttrs \u00b6 Classes using this metaclass can define a __prepare_attrs__ class method to manipulate the attributes available during the definition of any child classes. __prepare_attrs__ ( name , bases , attrs ) classmethod special \u00b6 Define this function in classes using this metaclass to manipulate the attributes available in subclass definitions. Important Any function defining __prepare_attrs__ should make sure it's idempotent in the attrs dictionary. Equivalently, the following should work for all possible name , bases ,and attrs : prep_attrs = lambda a : YourClass . __prepare_attrs__ ( name , bases , a ) assert ( prep_attrs ( attrs ) == prep_attrs ( prep_attrs ( attrs ))) Parameters: Name Type Description Default name str The name of the class being created required bases list list of classes this class is derived from required attrs dict The attributes defined by previous classes in the mro required Returns: Type Description dict The edited attrs dictionary that will be available to child classes as they're defined. The simplest possible version will just return the argument directly. get_future_mro ( name , bases ) classmethod \u00b6 Method to get the mro of a potential new class without triggering a number of class initialization and metaclass side-effects. Results are cached internal to the PrepareAttrs class object. Parameters: Name Type Description Default name str The name of the class you're getting an mro for required bases tuple A tuple of all the classes that the new one will directly inherit from. required Returns: Type Description list The mro that a hypothetical class with the given bases would have. get_stub_class ( cls ) classmethod \u00b6 Creates/retrieves a class object that is a side effect free version of another class. Parameters: Name Type Description Default cls class An external class required Returns: Type Description class An 'empty' stub with an identical mro to the parent class. This is cached and so will return the same stub class each time it's called on another class. Creating pre-init class attributes \u00b6 We can use PrepareAttrs to magically make a useful attribute class Test ( metaclass = PrepareAttrs ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): env [ 'test_var' ] = 15 return env Now any classes that derive from Test can use test_var within their class definition, ala: class Subtest ( Test ): subtest_var = test_var + 20 def run ( self ): print (( self . test_var , self . subtest_var )) Subtest () . run () The whole thing when run should print (15,35) . Note test_var and subtest_var become properties of the Subtest class , not any particular subtest object. If you're using a mutable value like a dictionary then updates will be shared between all the various objects involved unless you copy them in the object's __new__ or __init__ functions. Using prepare_attrs in a DSL \u00b6 In general this is meant to be used along with __init_subclass__ to enable more declarative DSLs in python, by allowing users to assign and manipulate terms directly in their new class definitions Here we're creating a rather contrived exampled where we allow subclasses to work with options directly and then validate them after the fact. class ValidateOptions ( metaclass = PrepareAttrs ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): env [ 'do_this' ] = True env [ 'do_that' ] = True env [ 'do_both' ] = True return env @classmethod def __init_subclass__ ( cls , ** kwargs ): super () . __init_subclass__ ( ** kwargs ) do_this = cls . __dict__ [ 'do_this' ] do_that = cls . __dict__ [ 'do_that' ] do_both = cls . __dict__ [ 'do_both' ] if ( do_this and do_that ) != do_both : raise RuntimeError ( \"Invalid Class Options\" ) class Test1 ( ValidateOptions ): do_this = False do_both = do_this and do_that class Test2 ( ValidateOptions ): do_both = False Notice how the user can both update and refer to settings information in their class definitions. This opens up the class definition as a place for declarations instead of just defining functions. Classes provide a nice modular grouping for your users as they interact with whatever system you're building a DSL for. That said, this example does have a few issues: The first issue is inheritance of properties. Consider adding the following class to our example: class Test3 ( Test1 ): def __init__ ( self ): print ( self . do_this ) Test3 () It would print True on init despite our Test1 class overriding the definition for do_this . - Similarly, out current setup doesn't take into account what happens when a child class overloads __prepare_attr__ . In particular if we have the following: class Test4 ( ValidateOptions ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): env [ 'something' ] = True return env class Test5 ( Test4 ): var = do_this We will get an error because do_this isn't defined into the context of Test5 . We'll discuss how to deal with these issues in the next few examples. Overloading prepare_attrs \u00b6 Before we deal with properly inheriting user made changes, we should look at how various calls to prepare_attr are handled when we have a sequence of classes inheriting from each other. from exam_gen.mixins.prepare_attrs import * class Base ( metaclass = PrepareAttrs ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): print (( name , cls . __name__ , \"Base.__prepare_attrs__\" )) return env class Test1 ( Base ): pass print ( \"\" ) # Space out print statements class Test2 ( Test1 ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): env = super () . __prepare_attrs__ ( name , bases , env ) print (( name , cls . __name__ , \"Test2.__prepare_attrs__\" )) return env print ( \"\" ) # Space out print statements class Test3 ( Test2 ): pass When run, the above example should print the following: ( 'Test1' , 'Base' , 'Base.__prepare_attrs__' ) ( 'Test2' , 'Base' , 'Base.__prepare_attrs__' ) ( 'Test2' , 'Test1' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Base' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test1' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test2' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test2' , 'Test2.__prepare_attrs__' ) The first line of that output means \"While generating the attrs for Test1 we are calling Base.__prepare_attrs__ with a class parameter of Base .\" and likewise for the rest of the lines. As expected, Test 1 has a single call from Base 's definition of prepare_attrs , which has access to the post-initialization version of the Base class. Looking at Test2 's calls we see something interesting. There are two separate calls to Base.__prepare_attrs__ , that have access to the post-init class definitions of Base and Test1 . We can use this to implement overloading. This is also why we ask for idempotence in your definitions of __prepare_attrs__ . Finally, we can take a look at Test3 's initialization: ( 'Test3' , 'Base' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test1' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test2' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test2' , 'Test2.__prepare_attrs__' ) This is what we want. Whatever preparation Base.__prepare_attrs__ does, it gets to do that prep for every class in Test3 's lineage. Likewise Test2.__prepare_attrs__ gets to do that prep for Test3 's environment. This is all because of that call to super() and without it we would get the following: ( 'Test3' , 'Base' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test1' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test2' , 'Test2.__prepare_attrs__' ) And completely forgo ('Test3', 'Test2', 'Base.__prepare_attrs__') and the corresponding call to Base.__prepare_attrs__ . Meaning that any changes to Test2 that are handled by Base 's handler would be missing. This would break any effort to update terms at each successive definition. Putting it all together \u00b6 So we're going to be making two classes that allow people to define and manipulate metadata about a class. Together they should provide a full example of how to use PrepareAttrs properly. The Metadata class \u00b6 The Metadata class allows the user to work with a single variable at class definition time, metadata which is a standard dictionary the user can edit. It uses __prepare_attrs__ to prepare the class environment, then in __init_subclass__ it prints that environment out to console. from pprint import * from exam_gen.mixins.prepare_attrs import * class Metadata ( metaclass = PrepareAttrs ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): print (( name , cls . __name__ , \"Metadata.__prepare_attrs__\" )) # Call metadata for superclasses if needed if hasattr ( super (), \"__prepare_attrs__\" ): env = super () . __prepare_attrs__ ( name , bases , env ) # If we don't have any metadata create it if 'metadata' not in env : env [ 'metadata' ] = {} # If the metadata has been changed in a class then # we can update it here. if hasattr ( cls , 'metadata' ): env [ 'metadata' ] . update ( cls . metadata ) return env @classmethod def __init_subclass__ ( cls , ** kwargs ): print (( cls . __name__ , \"ClassInfo.__init_subclass__\" )) if hasattr ( cls , \"metadata\" ): pprint ({ 'Class' : cls . __name__ , 'mro' : [ par . __qualname__ for par in cls . __mro__ ], 'Metadata at __init__' : cls . metadata }) As __init_subclass__ amounts to a bunch of print statements we can focus on __prepare_attrs__ . It meets the basic criteria we found in previous sections: Properly calls super().__prepare_attrs__ and keeps any updates that superclasses make to env . Does not re-initialize values in env if they already exist. Incorporates post-initialization changes from the cls parameter if they exist. (here via Dict.update() though other examples will probably be more complex. Returns the new modified env when finished. Adding ClassInfo to metadata \u00b6 This class inherits from Metadata and is largely identical. The only exceptions are a different print statement at the beginning and how instead of updating the metadata with each class call, it adds some information about parent classes: env [ 'metadata' ][ 'Base Classes' ] = [ base . __qualname__ for base in bases ] Initializing this class produces the following output: ( 'ClassInfo' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'ClassInfo' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'ClassInfo' , 'Metadata at __init__' : {}, 'mro' : [ 'ClassInfo' , 'Metadata' , 'object' ]} Which has the expected calls to Metadata.__prepare_attrs__ , and since you can't call ClassInfo.__prepare_attrs__ before there's a ClassInfo object there's no changes to the metadata other than the fact it exists. Setting metadata values \u00b6 Then we have Test1 , Test2 , and Test3 , which only set some metadata values: class Test1 ( Metadata ): metadata [ 'Name' ] = \"Walter\" class Test2 ( Metadata ): metadata [ 'Count' ] = 2 class Test3 ( Metadata ): metadata [ 'Name' ] = \"Beeswax\" And the corresponding output only shows that the values are set, and is otherwise uninteresting: ( 'Test1' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test1' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test1' , 'Metadata at __init__' : { 'Name' : 'Walter' }, 'mro' : [ 'Test1' , 'Metadata' , 'object' ]} ( 'Test2' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test2' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test2' , 'Metadata at __init__' : { 'Count' : 2 }, 'mro' : [ 'Test2' , 'Metadata' , 'object' ]} ( 'Test3' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test3' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test3' , 'Metadata at __init__' : { 'Name' : 'Beeswax' }, 'mro' : [ 'Test3' , 'Metadata' , 'object' ]} Inheritance order and overloading \u00b6 One of python's quirks is that the order of parent classes in your class declaration breaks ties in overloading. We want our metadata overloading system to have the same behavior. Both Test1 and Test3 define name so we can test this with the following: class Test4 ( Test1 , Test3 ): pass class Test5 ( Test3 , Test1 , ClassInfo ): pass Which produces the following output: ( 'Test4' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test4' , 'Test3' , 'Metadata.__prepare_attrs__' ) ( 'Test4' , 'Test1' , 'Metadata.__prepare_attrs__' ) ( 'Test4' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test4' , 'Metadata at __init__' : { 'Name' : 'Walter' }, 'mro' : [ 'Test4' , 'Test1' , 'Test3' , 'Metadata' , 'object' ]} ( 'Test5' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test5' , 'ClassInfo' , 'ClassInfo.__prepare_attrs__' ) ( 'Test5' , 'ClassInfo' , 'Metadata.__prepare_attrs__' ) ( 'Test5' , 'Test1' , 'Metadata.__prepare_attrs__' ) ( 'Test5' , 'Test3' , 'Metadata.__prepare_attrs__' ) ( 'Test5' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test5' , 'Metadata at __init__' : { 'Base Classes' : [ 'Test3' , 'Test1' , 'ClassInfo' ], 'Name' : 'Beeswax' }, 'mro' : [ 'Test5' , 'Test3' , 'Test1' , 'ClassInfo' , 'Metadata' , 'object' ]} Note how the correct name ends up being set in the metadata. In addition Test5 has both ClassInfo and Metadata correctly called during prep phase. Referencing properties set with prepare_attrs \u00b6 The following test cases access information within the metadata in addition to manipulating it. Test6 uses += to read and increment a value, similar functions could allow for many interesting and complex interactions in EDSLs. Test7 on the other hand is a simple test that confirms the class declaration environment functions just like any other imperative code environment. class Test6 ( Test1 , Test2 ): metadata [ 'Count' ] += 8 class Test7 ( Test6 , Test5 ): metadata [ 'Fruit' ] = \"Pineapple\" metadata [ 'Info' ] = \"Test7 has metadata for {} \" . format ( metadata . keys ()) metadata [ 'Pie' ] = \"Key Lime\" The output for Test6 confirms that the count from Test2 was correctly incremented as the class was initialized. ( 'Test6' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test6' , 'Test2' , 'Metadata.__prepare_attrs__' ) ( 'Test6' , 'Test1' , 'Metadata.__prepare_attrs__' ) ( 'Test6' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test6' , 'Metadata at __init__' : { 'Count' : 10 , 'Name' : 'Walter' }, 'mro' : [ 'Test6' , 'Test1' , 'Test2' , 'Metadata' , 'object' ]} The output for Test7 is a bit more verbose, but we can see that Pie was not included in Info , as metadata didn't have that key when the value for Info was generated. Output ( 'Test7' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'ClassInfo' , 'ClassInfo.__prepare_attrs__' ) ( 'Test7' , 'ClassInfo' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'Test2' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'Test1' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'Test3' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'Test5' , 'ClassInfo.__prepare_attrs__' ) ( 'Test7' , 'Test5' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'Test6' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test7' , 'Metadata at __init__' : { 'Base Classes' : [ 'Test6' , 'Test5' ], 'Count' : 10 , 'Fruit' : 'Pineapple' , 'Info' : \"Test7 has metadata for dict_keys(['Base \" \"Classes', 'Count', 'Name', 'Fruit'])\" , 'Name' : 'Walter' , 'Pie' : 'Key Lime' }, 'mro' : [ 'Test7' , 'Test6' , 'Test5' , 'Test3' , 'Test1' , 'Test2' , 'ClassInfo' , 'Metadata' , 'object' ]} Complete Example \u00b6 Example from pprint import * from exam_gen.mixins.prepare_attrs import * class Metadata ( metaclass = PrepareAttrs ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): print (( name , cls . __name__ , \"Metadata.__prepare_attrs__\" )) # Call metadata for superclasses if needed if hasattr ( super (), \"__prepare_attrs__\" ): env = super () . __prepare_attrs__ ( name , bases , env ) # If we don't have any metadata create it if 'metadata' not in env : env [ 'metadata' ] = {} # If the metadata has been changed in a class then # we can update it here. if hasattr ( cls , 'metadata' ): env [ 'metadata' ] . update ( cls . metadata ) return env @classmethod def __init_subclass__ ( cls , ** kwargs ): print (( cls . __name__ , \"ClassInfo.__init_subclass__\" )) if hasattr ( cls , \"metadata\" ): pprint ({ 'Class' : cls . __name__ , 'mro' : [ par . __qualname__ for par in cls . __mro__ ], 'Metadata at __init__' : cls . metadata }) print ( \"\" ) class ClassInfo ( Metadata ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): print (( name , cls . __name__ , \"ClassInfo.__prepare_attrs__\" )) # Call metadata for superclasses if needed if hasattr ( super (), \"__prepare_attrs__\" ): env = super () . __prepare_attrs__ ( name , bases , env ) # If we don't have any metadata create it if 'metadata' not in env : env [ 'metadata' ] = {} # If the metadata has been changed in a class then # we can update it here. if hasattr ( cls , 'metadata' ): env [ 'metadata' ][ 'Base Classes' ] = [ base . __qualname__ for base in bases ] return env print ( \"\" ) class Test1 ( Metadata ): metadata [ 'Name' ] = \"Walter\" print ( \"\" ) class Test2 ( Metadata ): metadata [ 'Count' ] = 2 print ( \"\" ) class Test3 ( Metadata ): metadata [ 'Name' ] = \"Beeswax\" print ( \"\" ) class Test4 ( Test1 , Test3 ): pass print ( \"\" ) class Test5 ( Test3 , Test1 , ClassInfo ): pass print ( \"\" ) class Test6 ( Test1 , Test2 ): metadata [ 'Count' ] += 8 print ( \"\" ) class Test7 ( Test6 , Test5 ): metadata [ 'Fruit' ] = \"Pineapple\" metadata [ 'Info' ] = \"Test7 has metadata for {} \" . format ( metadata . keys ()) metadata [ 'Pie' ] = \"Key Lime\" Output ('ClassInfo', 'Metadata', 'Metadata.__prepare_attrs__') ('ClassInfo', 'ClassInfo.__init_subclass__') {'Class': 'ClassInfo', 'Metadata at __init__': {}, 'mro': ['ClassInfo', 'Metadata', 'object']} ('Test1', 'Metadata', 'Metadata.__prepare_attrs__') ('Test1', 'ClassInfo.__init_subclass__') {'Class': 'Test1', 'Metadata at __init__': {'Name': 'Walter'}, 'mro': ['Test1', 'Metadata', 'object']} ('Test2', 'Metadata', 'Metadata.__prepare_attrs__') ('Test2', 'ClassInfo.__init_subclass__') {'Class': 'Test2', 'Metadata at __init__': {'Count': 2}, 'mro': ['Test2', 'Metadata', 'object']} ('Test3', 'Metadata', 'Metadata.__prepare_attrs__') ('Test3', 'ClassInfo.__init_subclass__') {'Class': 'Test3', 'Metadata at __init__': {'Name': 'Beeswax'}, 'mro': ['Test3', 'Metadata', 'object']} ('Test4', 'Metadata', 'Metadata.__prepare_attrs__') ('Test4', 'Test3', 'Metadata.__prepare_attrs__') ('Test4', 'Test1', 'Metadata.__prepare_attrs__') ('Test4', 'ClassInfo.__init_subclass__') {'Class': 'Test4', 'Metadata at __init__': {'Name': 'Walter'}, 'mro': ['Test4', 'Test1', 'Test3', 'Metadata', 'object']} ('Test5', 'Metadata', 'Metadata.__prepare_attrs__') ('Test5', 'ClassInfo', 'ClassInfo.__prepare_attrs__') ('Test5', 'ClassInfo', 'Metadata.__prepare_attrs__') ('Test5', 'Test1', 'Metadata.__prepare_attrs__') ('Test5', 'Test3', 'Metadata.__prepare_attrs__') ('Test5', 'ClassInfo.__init_subclass__') {'Class': 'Test5', 'Metadata at __init__': {'Base Classes': ['Test3', 'Test1', 'ClassInfo'], 'Name': 'Beeswax'}, 'mro': ['Test5', 'Test3', 'Test1', 'ClassInfo', 'Metadata', 'object']} ('Test6', 'Metadata', 'Metadata.__prepare_attrs__') ('Test6', 'Test2', 'Metadata.__prepare_attrs__') ('Test6', 'Test1', 'Metadata.__prepare_attrs__') ('Test6', 'ClassInfo.__init_subclass__') {'Class': 'Test6', 'Metadata at __init__': {'Count': 10, 'Name': 'Walter'}, 'mro': ['Test6', 'Test1', 'Test2', 'Metadata', 'object']} ('Test7', 'Metadata', 'Metadata.__prepare_attrs__') ('Test7', 'ClassInfo', 'ClassInfo.__prepare_attrs__') ('Test7', 'ClassInfo', 'Metadata.__prepare_attrs__') ('Test7', 'Test2', 'Metadata.__prepare_attrs__') ('Test7', 'Test1', 'Metadata.__prepare_attrs__') ('Test7', 'Test3', 'Metadata.__prepare_attrs__') ('Test7', 'Test5', 'ClassInfo.__prepare_attrs__') ('Test7', 'Test5', 'Metadata.__prepare_attrs__') ('Test7', 'Test6', 'Metadata.__prepare_attrs__') ('Test7', 'ClassInfo.__init_subclass__') {'Class': 'Test7', 'Metadata at __init__': {'Base Classes': ['Test6', 'Test5'], 'Count': 10, 'Fruit': 'Pineapple', 'Info': \"Test7 has metadata for dict_keys(['Base \" \"Classes', 'Count', 'Name', 'Fruit'])\", 'Name': 'Walter', 'Pie': 'Key Lime'}, 'mro': ['Test7', 'Test6', 'Test5', 'Test3', 'Test1', 'Test2', 'ClassInfo', 'Metadata', 'object']}","title":"PrepareAttrs"},{"location":"api/mixins/prepare_attrs.html#prepareattrs-metaclass","text":"This metaclass makes it easier to control and manipulate the variables available during the class definition process, and has a lot of utility in making class-based EDSLs more elegant. Python already has the __init_subclass__ and __dict__ mechanisms for working with declaration statements in a class definition. These are great, but they're only capable of handling the environment of a class after a user has interacted with it. PrepareAttrs gives EDSL authors a way to prepare that environment beforehand and get a lot of additional power. Warning Only the final section has a full example. The other sections of this page use working but flawed examples to build up necessary information needed to understand the full function of the final example.","title":"PrepareAttrs Metaclass"},{"location":"api/mixins/prepare_attrs.html#generated-documentation","text":"","title":"Generated Documentation"},{"location":"api/mixins/prepare_attrs.html#exam_gen.mixins.prepare_attrs.PrepareAttrs","text":"Classes using this metaclass can define a __prepare_attrs__ class method to manipulate the attributes available during the definition of any child classes.","title":"PrepareAttrs"},{"location":"api/mixins/prepare_attrs.html#exam_gen.mixins.prepare_attrs.PrepareAttrs.__prepare_attrs__","text":"Define this function in classes using this metaclass to manipulate the attributes available in subclass definitions. Important Any function defining __prepare_attrs__ should make sure it's idempotent in the attrs dictionary. Equivalently, the following should work for all possible name , bases ,and attrs : prep_attrs = lambda a : YourClass . __prepare_attrs__ ( name , bases , a ) assert ( prep_attrs ( attrs ) == prep_attrs ( prep_attrs ( attrs ))) Parameters: Name Type Description Default name str The name of the class being created required bases list list of classes this class is derived from required attrs dict The attributes defined by previous classes in the mro required Returns: Type Description dict The edited attrs dictionary that will be available to child classes as they're defined. The simplest possible version will just return the argument directly.","title":"__prepare_attrs__()"},{"location":"api/mixins/prepare_attrs.html#exam_gen.mixins.prepare_attrs.PrepareAttrs.get_future_mro","text":"Method to get the mro of a potential new class without triggering a number of class initialization and metaclass side-effects. Results are cached internal to the PrepareAttrs class object. Parameters: Name Type Description Default name str The name of the class you're getting an mro for required bases tuple A tuple of all the classes that the new one will directly inherit from. required Returns: Type Description list The mro that a hypothetical class with the given bases would have.","title":"get_future_mro()"},{"location":"api/mixins/prepare_attrs.html#exam_gen.mixins.prepare_attrs.PrepareAttrs.get_stub_class","text":"Creates/retrieves a class object that is a side effect free version of another class. Parameters: Name Type Description Default cls class An external class required Returns: Type Description class An 'empty' stub with an identical mro to the parent class. This is cached and so will return the same stub class each time it's called on another class.","title":"get_stub_class()"},{"location":"api/mixins/prepare_attrs.html#creating-pre-init-class-attributes","text":"We can use PrepareAttrs to magically make a useful attribute class Test ( metaclass = PrepareAttrs ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): env [ 'test_var' ] = 15 return env Now any classes that derive from Test can use test_var within their class definition, ala: class Subtest ( Test ): subtest_var = test_var + 20 def run ( self ): print (( self . test_var , self . subtest_var )) Subtest () . run () The whole thing when run should print (15,35) . Note test_var and subtest_var become properties of the Subtest class , not any particular subtest object. If you're using a mutable value like a dictionary then updates will be shared between all the various objects involved unless you copy them in the object's __new__ or __init__ functions.","title":"Creating pre-init class attributes"},{"location":"api/mixins/prepare_attrs.html#using-prepare_attrs-in-a-dsl","text":"In general this is meant to be used along with __init_subclass__ to enable more declarative DSLs in python, by allowing users to assign and manipulate terms directly in their new class definitions Here we're creating a rather contrived exampled where we allow subclasses to work with options directly and then validate them after the fact. class ValidateOptions ( metaclass = PrepareAttrs ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): env [ 'do_this' ] = True env [ 'do_that' ] = True env [ 'do_both' ] = True return env @classmethod def __init_subclass__ ( cls , ** kwargs ): super () . __init_subclass__ ( ** kwargs ) do_this = cls . __dict__ [ 'do_this' ] do_that = cls . __dict__ [ 'do_that' ] do_both = cls . __dict__ [ 'do_both' ] if ( do_this and do_that ) != do_both : raise RuntimeError ( \"Invalid Class Options\" ) class Test1 ( ValidateOptions ): do_this = False do_both = do_this and do_that class Test2 ( ValidateOptions ): do_both = False Notice how the user can both update and refer to settings information in their class definitions. This opens up the class definition as a place for declarations instead of just defining functions. Classes provide a nice modular grouping for your users as they interact with whatever system you're building a DSL for. That said, this example does have a few issues: The first issue is inheritance of properties. Consider adding the following class to our example: class Test3 ( Test1 ): def __init__ ( self ): print ( self . do_this ) Test3 () It would print True on init despite our Test1 class overriding the definition for do_this . - Similarly, out current setup doesn't take into account what happens when a child class overloads __prepare_attr__ . In particular if we have the following: class Test4 ( ValidateOptions ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): env [ 'something' ] = True return env class Test5 ( Test4 ): var = do_this We will get an error because do_this isn't defined into the context of Test5 . We'll discuss how to deal with these issues in the next few examples.","title":"Using prepare_attrs in a DSL"},{"location":"api/mixins/prepare_attrs.html#overloading-prepare_attrs","text":"Before we deal with properly inheriting user made changes, we should look at how various calls to prepare_attr are handled when we have a sequence of classes inheriting from each other. from exam_gen.mixins.prepare_attrs import * class Base ( metaclass = PrepareAttrs ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): print (( name , cls . __name__ , \"Base.__prepare_attrs__\" )) return env class Test1 ( Base ): pass print ( \"\" ) # Space out print statements class Test2 ( Test1 ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): env = super () . __prepare_attrs__ ( name , bases , env ) print (( name , cls . __name__ , \"Test2.__prepare_attrs__\" )) return env print ( \"\" ) # Space out print statements class Test3 ( Test2 ): pass When run, the above example should print the following: ( 'Test1' , 'Base' , 'Base.__prepare_attrs__' ) ( 'Test2' , 'Base' , 'Base.__prepare_attrs__' ) ( 'Test2' , 'Test1' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Base' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test1' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test2' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test2' , 'Test2.__prepare_attrs__' ) The first line of that output means \"While generating the attrs for Test1 we are calling Base.__prepare_attrs__ with a class parameter of Base .\" and likewise for the rest of the lines. As expected, Test 1 has a single call from Base 's definition of prepare_attrs , which has access to the post-initialization version of the Base class. Looking at Test2 's calls we see something interesting. There are two separate calls to Base.__prepare_attrs__ , that have access to the post-init class definitions of Base and Test1 . We can use this to implement overloading. This is also why we ask for idempotence in your definitions of __prepare_attrs__ . Finally, we can take a look at Test3 's initialization: ( 'Test3' , 'Base' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test1' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test2' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test2' , 'Test2.__prepare_attrs__' ) This is what we want. Whatever preparation Base.__prepare_attrs__ does, it gets to do that prep for every class in Test3 's lineage. Likewise Test2.__prepare_attrs__ gets to do that prep for Test3 's environment. This is all because of that call to super() and without it we would get the following: ( 'Test3' , 'Base' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test1' , 'Base.__prepare_attrs__' ) ( 'Test3' , 'Test2' , 'Test2.__prepare_attrs__' ) And completely forgo ('Test3', 'Test2', 'Base.__prepare_attrs__') and the corresponding call to Base.__prepare_attrs__ . Meaning that any changes to Test2 that are handled by Base 's handler would be missing. This would break any effort to update terms at each successive definition.","title":"Overloading prepare_attrs"},{"location":"api/mixins/prepare_attrs.html#putting-it-all-together","text":"So we're going to be making two classes that allow people to define and manipulate metadata about a class. Together they should provide a full example of how to use PrepareAttrs properly.","title":"Putting it all together"},{"location":"api/mixins/prepare_attrs.html#the-metadata-class","text":"The Metadata class allows the user to work with a single variable at class definition time, metadata which is a standard dictionary the user can edit. It uses __prepare_attrs__ to prepare the class environment, then in __init_subclass__ it prints that environment out to console. from pprint import * from exam_gen.mixins.prepare_attrs import * class Metadata ( metaclass = PrepareAttrs ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): print (( name , cls . __name__ , \"Metadata.__prepare_attrs__\" )) # Call metadata for superclasses if needed if hasattr ( super (), \"__prepare_attrs__\" ): env = super () . __prepare_attrs__ ( name , bases , env ) # If we don't have any metadata create it if 'metadata' not in env : env [ 'metadata' ] = {} # If the metadata has been changed in a class then # we can update it here. if hasattr ( cls , 'metadata' ): env [ 'metadata' ] . update ( cls . metadata ) return env @classmethod def __init_subclass__ ( cls , ** kwargs ): print (( cls . __name__ , \"ClassInfo.__init_subclass__\" )) if hasattr ( cls , \"metadata\" ): pprint ({ 'Class' : cls . __name__ , 'mro' : [ par . __qualname__ for par in cls . __mro__ ], 'Metadata at __init__' : cls . metadata }) As __init_subclass__ amounts to a bunch of print statements we can focus on __prepare_attrs__ . It meets the basic criteria we found in previous sections: Properly calls super().__prepare_attrs__ and keeps any updates that superclasses make to env . Does not re-initialize values in env if they already exist. Incorporates post-initialization changes from the cls parameter if they exist. (here via Dict.update() though other examples will probably be more complex. Returns the new modified env when finished.","title":"The Metadata class"},{"location":"api/mixins/prepare_attrs.html#adding-classinfo-to-metadata","text":"This class inherits from Metadata and is largely identical. The only exceptions are a different print statement at the beginning and how instead of updating the metadata with each class call, it adds some information about parent classes: env [ 'metadata' ][ 'Base Classes' ] = [ base . __qualname__ for base in bases ] Initializing this class produces the following output: ( 'ClassInfo' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'ClassInfo' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'ClassInfo' , 'Metadata at __init__' : {}, 'mro' : [ 'ClassInfo' , 'Metadata' , 'object' ]} Which has the expected calls to Metadata.__prepare_attrs__ , and since you can't call ClassInfo.__prepare_attrs__ before there's a ClassInfo object there's no changes to the metadata other than the fact it exists.","title":"Adding ClassInfo to metadata"},{"location":"api/mixins/prepare_attrs.html#setting-metadata-values","text":"Then we have Test1 , Test2 , and Test3 , which only set some metadata values: class Test1 ( Metadata ): metadata [ 'Name' ] = \"Walter\" class Test2 ( Metadata ): metadata [ 'Count' ] = 2 class Test3 ( Metadata ): metadata [ 'Name' ] = \"Beeswax\" And the corresponding output only shows that the values are set, and is otherwise uninteresting: ( 'Test1' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test1' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test1' , 'Metadata at __init__' : { 'Name' : 'Walter' }, 'mro' : [ 'Test1' , 'Metadata' , 'object' ]} ( 'Test2' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test2' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test2' , 'Metadata at __init__' : { 'Count' : 2 }, 'mro' : [ 'Test2' , 'Metadata' , 'object' ]} ( 'Test3' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test3' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test3' , 'Metadata at __init__' : { 'Name' : 'Beeswax' }, 'mro' : [ 'Test3' , 'Metadata' , 'object' ]}","title":"Setting metadata values"},{"location":"api/mixins/prepare_attrs.html#inheritance-order-and-overloading","text":"One of python's quirks is that the order of parent classes in your class declaration breaks ties in overloading. We want our metadata overloading system to have the same behavior. Both Test1 and Test3 define name so we can test this with the following: class Test4 ( Test1 , Test3 ): pass class Test5 ( Test3 , Test1 , ClassInfo ): pass Which produces the following output: ( 'Test4' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test4' , 'Test3' , 'Metadata.__prepare_attrs__' ) ( 'Test4' , 'Test1' , 'Metadata.__prepare_attrs__' ) ( 'Test4' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test4' , 'Metadata at __init__' : { 'Name' : 'Walter' }, 'mro' : [ 'Test4' , 'Test1' , 'Test3' , 'Metadata' , 'object' ]} ( 'Test5' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test5' , 'ClassInfo' , 'ClassInfo.__prepare_attrs__' ) ( 'Test5' , 'ClassInfo' , 'Metadata.__prepare_attrs__' ) ( 'Test5' , 'Test1' , 'Metadata.__prepare_attrs__' ) ( 'Test5' , 'Test3' , 'Metadata.__prepare_attrs__' ) ( 'Test5' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test5' , 'Metadata at __init__' : { 'Base Classes' : [ 'Test3' , 'Test1' , 'ClassInfo' ], 'Name' : 'Beeswax' }, 'mro' : [ 'Test5' , 'Test3' , 'Test1' , 'ClassInfo' , 'Metadata' , 'object' ]} Note how the correct name ends up being set in the metadata. In addition Test5 has both ClassInfo and Metadata correctly called during prep phase.","title":"Inheritance order and overloading"},{"location":"api/mixins/prepare_attrs.html#referencing-properties-set-with-prepare_attrs","text":"The following test cases access information within the metadata in addition to manipulating it. Test6 uses += to read and increment a value, similar functions could allow for many interesting and complex interactions in EDSLs. Test7 on the other hand is a simple test that confirms the class declaration environment functions just like any other imperative code environment. class Test6 ( Test1 , Test2 ): metadata [ 'Count' ] += 8 class Test7 ( Test6 , Test5 ): metadata [ 'Fruit' ] = \"Pineapple\" metadata [ 'Info' ] = \"Test7 has metadata for {} \" . format ( metadata . keys ()) metadata [ 'Pie' ] = \"Key Lime\" The output for Test6 confirms that the count from Test2 was correctly incremented as the class was initialized. ( 'Test6' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test6' , 'Test2' , 'Metadata.__prepare_attrs__' ) ( 'Test6' , 'Test1' , 'Metadata.__prepare_attrs__' ) ( 'Test6' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test6' , 'Metadata at __init__' : { 'Count' : 10 , 'Name' : 'Walter' }, 'mro' : [ 'Test6' , 'Test1' , 'Test2' , 'Metadata' , 'object' ]} The output for Test7 is a bit more verbose, but we can see that Pie was not included in Info , as metadata didn't have that key when the value for Info was generated. Output ( 'Test7' , 'Metadata' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'ClassInfo' , 'ClassInfo.__prepare_attrs__' ) ( 'Test7' , 'ClassInfo' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'Test2' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'Test1' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'Test3' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'Test5' , 'ClassInfo.__prepare_attrs__' ) ( 'Test7' , 'Test5' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'Test6' , 'Metadata.__prepare_attrs__' ) ( 'Test7' , 'ClassInfo.__init_subclass__' ) { 'Class' : 'Test7' , 'Metadata at __init__' : { 'Base Classes' : [ 'Test6' , 'Test5' ], 'Count' : 10 , 'Fruit' : 'Pineapple' , 'Info' : \"Test7 has metadata for dict_keys(['Base \" \"Classes', 'Count', 'Name', 'Fruit'])\" , 'Name' : 'Walter' , 'Pie' : 'Key Lime' }, 'mro' : [ 'Test7' , 'Test6' , 'Test5' , 'Test3' , 'Test1' , 'Test2' , 'ClassInfo' , 'Metadata' , 'object' ]}","title":"Referencing properties set with prepare_attrs"},{"location":"api/mixins/prepare_attrs.html#complete-example","text":"Example from pprint import * from exam_gen.mixins.prepare_attrs import * class Metadata ( metaclass = PrepareAttrs ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): print (( name , cls . __name__ , \"Metadata.__prepare_attrs__\" )) # Call metadata for superclasses if needed if hasattr ( super (), \"__prepare_attrs__\" ): env = super () . __prepare_attrs__ ( name , bases , env ) # If we don't have any metadata create it if 'metadata' not in env : env [ 'metadata' ] = {} # If the metadata has been changed in a class then # we can update it here. if hasattr ( cls , 'metadata' ): env [ 'metadata' ] . update ( cls . metadata ) return env @classmethod def __init_subclass__ ( cls , ** kwargs ): print (( cls . __name__ , \"ClassInfo.__init_subclass__\" )) if hasattr ( cls , \"metadata\" ): pprint ({ 'Class' : cls . __name__ , 'mro' : [ par . __qualname__ for par in cls . __mro__ ], 'Metadata at __init__' : cls . metadata }) print ( \"\" ) class ClassInfo ( Metadata ): @classmethod def __prepare_attrs__ ( cls , name , bases , env ): print (( name , cls . __name__ , \"ClassInfo.__prepare_attrs__\" )) # Call metadata for superclasses if needed if hasattr ( super (), \"__prepare_attrs__\" ): env = super () . __prepare_attrs__ ( name , bases , env ) # If we don't have any metadata create it if 'metadata' not in env : env [ 'metadata' ] = {} # If the metadata has been changed in a class then # we can update it here. if hasattr ( cls , 'metadata' ): env [ 'metadata' ][ 'Base Classes' ] = [ base . __qualname__ for base in bases ] return env print ( \"\" ) class Test1 ( Metadata ): metadata [ 'Name' ] = \"Walter\" print ( \"\" ) class Test2 ( Metadata ): metadata [ 'Count' ] = 2 print ( \"\" ) class Test3 ( Metadata ): metadata [ 'Name' ] = \"Beeswax\" print ( \"\" ) class Test4 ( Test1 , Test3 ): pass print ( \"\" ) class Test5 ( Test3 , Test1 , ClassInfo ): pass print ( \"\" ) class Test6 ( Test1 , Test2 ): metadata [ 'Count' ] += 8 print ( \"\" ) class Test7 ( Test6 , Test5 ): metadata [ 'Fruit' ] = \"Pineapple\" metadata [ 'Info' ] = \"Test7 has metadata for {} \" . format ( metadata . keys ()) metadata [ 'Pie' ] = \"Key Lime\" Output ('ClassInfo', 'Metadata', 'Metadata.__prepare_attrs__') ('ClassInfo', 'ClassInfo.__init_subclass__') {'Class': 'ClassInfo', 'Metadata at __init__': {}, 'mro': ['ClassInfo', 'Metadata', 'object']} ('Test1', 'Metadata', 'Metadata.__prepare_attrs__') ('Test1', 'ClassInfo.__init_subclass__') {'Class': 'Test1', 'Metadata at __init__': {'Name': 'Walter'}, 'mro': ['Test1', 'Metadata', 'object']} ('Test2', 'Metadata', 'Metadata.__prepare_attrs__') ('Test2', 'ClassInfo.__init_subclass__') {'Class': 'Test2', 'Metadata at __init__': {'Count': 2}, 'mro': ['Test2', 'Metadata', 'object']} ('Test3', 'Metadata', 'Metadata.__prepare_attrs__') ('Test3', 'ClassInfo.__init_subclass__') {'Class': 'Test3', 'Metadata at __init__': {'Name': 'Beeswax'}, 'mro': ['Test3', 'Metadata', 'object']} ('Test4', 'Metadata', 'Metadata.__prepare_attrs__') ('Test4', 'Test3', 'Metadata.__prepare_attrs__') ('Test4', 'Test1', 'Metadata.__prepare_attrs__') ('Test4', 'ClassInfo.__init_subclass__') {'Class': 'Test4', 'Metadata at __init__': {'Name': 'Walter'}, 'mro': ['Test4', 'Test1', 'Test3', 'Metadata', 'object']} ('Test5', 'Metadata', 'Metadata.__prepare_attrs__') ('Test5', 'ClassInfo', 'ClassInfo.__prepare_attrs__') ('Test5', 'ClassInfo', 'Metadata.__prepare_attrs__') ('Test5', 'Test1', 'Metadata.__prepare_attrs__') ('Test5', 'Test3', 'Metadata.__prepare_attrs__') ('Test5', 'ClassInfo.__init_subclass__') {'Class': 'Test5', 'Metadata at __init__': {'Base Classes': ['Test3', 'Test1', 'ClassInfo'], 'Name': 'Beeswax'}, 'mro': ['Test5', 'Test3', 'Test1', 'ClassInfo', 'Metadata', 'object']} ('Test6', 'Metadata', 'Metadata.__prepare_attrs__') ('Test6', 'Test2', 'Metadata.__prepare_attrs__') ('Test6', 'Test1', 'Metadata.__prepare_attrs__') ('Test6', 'ClassInfo.__init_subclass__') {'Class': 'Test6', 'Metadata at __init__': {'Count': 10, 'Name': 'Walter'}, 'mro': ['Test6', 'Test1', 'Test2', 'Metadata', 'object']} ('Test7', 'Metadata', 'Metadata.__prepare_attrs__') ('Test7', 'ClassInfo', 'ClassInfo.__prepare_attrs__') ('Test7', 'ClassInfo', 'Metadata.__prepare_attrs__') ('Test7', 'Test2', 'Metadata.__prepare_attrs__') ('Test7', 'Test1', 'Metadata.__prepare_attrs__') ('Test7', 'Test3', 'Metadata.__prepare_attrs__') ('Test7', 'Test5', 'ClassInfo.__prepare_attrs__') ('Test7', 'Test5', 'Metadata.__prepare_attrs__') ('Test7', 'Test6', 'Metadata.__prepare_attrs__') ('Test7', 'ClassInfo.__init_subclass__') {'Class': 'Test7', 'Metadata at __init__': {'Base Classes': ['Test6', 'Test5'], 'Count': 10, 'Fruit': 'Pineapple', 'Info': \"Test7 has metadata for dict_keys(['Base \" \"Classes', 'Count', 'Name', 'Fruit'])\", 'Name': 'Walter', 'Pie': 'Key Lime'}, 'mro': ['Test7', 'Test6', 'Test5', 'Test3', 'Test1', 'Test2', 'ClassInfo', 'Metadata', 'object']}","title":"Complete Example"},{"location":"api/mixins/settings.html","text":"Settings Manager \u00b6 Classes that inherit from SettingsManager will gain a settings property that acts like a dictionary of various runtime options. It also will perform validation of options, auto-generate documentation, and provide other features that enable a smoother user experience. Generated Documentation \u00b6 SettingsManager \u00b6 A class that inherits from this settings manager will given a settings attribute with various options and autogenerate documentation from the different parent options given. __init__ ( self , ** kwargs ) special \u00b6 __init_subclass__ ( ** kwargs ) classmethod special \u00b6 User Docs \u00b6 Reading Options \u00b6 In class declarations \u00b6 class Foo : test_file = settings . data_file_dir + \"/test.txt\" At Runtime \u00b6 class Foo : def init ( self ): self . test_file = self . settings . data_file_dir + \"/test.txt\" Settings Options \u00b6 Single Option \u00b6 In class decls: class Foo : settings . template_file = \"template.txt\" At runtime: class Foo : def init ( self ): self . settings . template_file = \"template.txt\" Bulk Update \u00b6 In class decls: class Foo : settings += { 'template_file' : \"template.txt\" , 'shuffle_choices' : range ( 0 , settings . num_choices - 1 ) 'metadata' : { 'author' : \"Jane Doe\" , 'date_written' : \"12/31/2014\" } At runtime: class Foo : def init ( self ): self . settings += { 'template_file' : \"template.txt\" , 'shuffle_choices' : range ( 0 , self . settings . num_choices - 1 ) 'metadata' : { 'author' : \"Jane Doe\" , 'date_written' : \"12/31/2014\" } Developer Docs \u00b6 Adding new options \u00b6 Looks similar to user writing of options with additional define_option function, that has various kwargs. def Foo ( SettingsManager ): settings . num_cats = define_option ( default = None , short_desc = \"Number of cats\" , ... ) Also works in bulk mode: def Foo ( SettingsManager ): settings += { 'num_cats' : define_option ( default = None , short_desc = \"Number of cats\" , ... ), 'dog_park' : \"Midtown Park\" , 'dog_breed' : define_option ( ... ) } We cover the various possible arguments in the following subsections. Important New options can only be defined in class declarations. Unlike the user options, trying to define or update options at runtime is an error. Documentation \u00b6 short_desc : Short string describing option long_desc : Long string (in docs style markdown) describing option. Will be trimmed and dedented before use. Defaults \u00b6 default : The default value if not overridden by user or other subclass Validation \u00b6 validator : lambda or function that returns true if the value is valid and false otherwise. First argument is the option itself, second optional arg is the entire settings object as a whole. Single arg: def Foo ( SettingsManager ): settings . num_choices = define_option ( default = 4 , validator = lambda n : n > 1 and n <= 26 , ... ) Dual arg: def Foo ( SettingsManager ): settings . data_file = define_option ( default = 4 , validator = lambda file , settings : file_exists ( settings . data_dir + file ), ... ) Important Accessing settings without the dual arg version of the validator might get the wrong value for a setting, before sublasses or the user changes it. validation_error : Error message for an invalid option string : Can be a static string lambda : Can be a lambda or function that returns a string with between 1 and 3 params. val : The value being validated settings : The root settings object in its current state metadata : (As yet undefined) Metadata about where the error occurred and stuff. Note Validation is generally not automatic and needs to be invoked by a subclass of SettingsManager , as we can't expect settings information to be in a valid state at every point in the class definition process. Automatic Derivation \u00b6 derivation : Lambda or function that will generate the value from other settings information. The parameter is the root settings object. derive_on_read : Bool for whether we should try to derive this value automatically on a read attempt. Mandatory settings \u00b6 required : Bool for whether the setting must be defined at validation time. Treats an unset value or None as a validation error. (default = False ) Read-Only settings \u00b6 read_only : Bool for whether the setting should be writable. Read only terms can only be changed by using update_option to set read_only to False first. Update functions \u00b6 update_with : lambda or function with 2 or 3 arguments that intercepts any attempts to set a value directly and allows you to merge or format the values as needed. Arg 1 old : The old value. Will be the default or None if no value is set Arg 2 new : The new value Optional Arg 3 settings : the root settings object you're working with. Note: modifying other settings with this might cause inconsistent results in edge cases. Copy function \u00b6 copy_func : one parameter lambda or function to be used when we're copying a settings object internally. We need to internally deep copy the full settings tree when we're generating each subclass's data. Aliases \u00b6 Use define_alias to make two options refer to the same value. def Foo ( SettingsManager ): settings . num_cats = define_alias ( 'animal_counts.cats' ) The input should be relative to the root settings object and either: - A . delineated string like in the example - Or a list like ['animal_counts','cats'] which would be equivalent to the example. Updating existing options \u00b6 Use update_option to change the properties of a term which already exists. Options are identical to define_option and will overwrite those options. These are separate functions and come with appropriate existence checks. Overloading and inheritance \u00b6 Integrating validation \u00b6 Todo Probably we'll have some sort of validate , validate_given , and validate_all functions or something. Error messages \u00b6 Documentation generation \u00b6 Option provenance tracking \u00b6 Duplication on object init \u00b6 Internal/Implementation Documentation \u00b6","title":"Settings"},{"location":"api/mixins/settings.html#settings-manager","text":"Classes that inherit from SettingsManager will gain a settings property that acts like a dictionary of various runtime options. It also will perform validation of options, auto-generate documentation, and provide other features that enable a smoother user experience.","title":"Settings Manager"},{"location":"api/mixins/settings.html#generated-documentation","text":"","title":"Generated Documentation"},{"location":"api/mixins/settings.html#exam_gen.mixins.settings.SettingsManager","text":"A class that inherits from this settings manager will given a settings attribute with various options and autogenerate documentation from the different parent options given.","title":"SettingsManager"},{"location":"api/mixins/settings.html#exam_gen.mixins.settings.SettingsManager.__init__","text":"","title":"__init__()"},{"location":"api/mixins/settings.html#exam_gen.mixins.settings.SettingsManager.__init_subclass__","text":"","title":"__init_subclass__()"},{"location":"api/mixins/settings.html#user-docs","text":"","title":"User Docs"},{"location":"api/mixins/settings.html#reading-options","text":"","title":"Reading Options"},{"location":"api/mixins/settings.html#in-class-declarations","text":"class Foo : test_file = settings . data_file_dir + \"/test.txt\"","title":"In class declarations"},{"location":"api/mixins/settings.html#at-runtime","text":"class Foo : def init ( self ): self . test_file = self . settings . data_file_dir + \"/test.txt\"","title":"At Runtime"},{"location":"api/mixins/settings.html#settings-options","text":"","title":"Settings Options"},{"location":"api/mixins/settings.html#single-option","text":"In class decls: class Foo : settings . template_file = \"template.txt\" At runtime: class Foo : def init ( self ): self . settings . template_file = \"template.txt\"","title":"Single Option"},{"location":"api/mixins/settings.html#bulk-update","text":"In class decls: class Foo : settings += { 'template_file' : \"template.txt\" , 'shuffle_choices' : range ( 0 , settings . num_choices - 1 ) 'metadata' : { 'author' : \"Jane Doe\" , 'date_written' : \"12/31/2014\" } At runtime: class Foo : def init ( self ): self . settings += { 'template_file' : \"template.txt\" , 'shuffle_choices' : range ( 0 , self . settings . num_choices - 1 ) 'metadata' : { 'author' : \"Jane Doe\" , 'date_written' : \"12/31/2014\" }","title":"Bulk Update"},{"location":"api/mixins/settings.html#developer-docs","text":"","title":"Developer Docs"},{"location":"api/mixins/settings.html#adding-new-options","text":"Looks similar to user writing of options with additional define_option function, that has various kwargs. def Foo ( SettingsManager ): settings . num_cats = define_option ( default = None , short_desc = \"Number of cats\" , ... ) Also works in bulk mode: def Foo ( SettingsManager ): settings += { 'num_cats' : define_option ( default = None , short_desc = \"Number of cats\" , ... ), 'dog_park' : \"Midtown Park\" , 'dog_breed' : define_option ( ... ) } We cover the various possible arguments in the following subsections. Important New options can only be defined in class declarations. Unlike the user options, trying to define or update options at runtime is an error.","title":"Adding new options"},{"location":"api/mixins/settings.html#documentation","text":"short_desc : Short string describing option long_desc : Long string (in docs style markdown) describing option. Will be trimmed and dedented before use.","title":"Documentation"},{"location":"api/mixins/settings.html#defaults","text":"default : The default value if not overridden by user or other subclass","title":"Defaults"},{"location":"api/mixins/settings.html#validation","text":"validator : lambda or function that returns true if the value is valid and false otherwise. First argument is the option itself, second optional arg is the entire settings object as a whole. Single arg: def Foo ( SettingsManager ): settings . num_choices = define_option ( default = 4 , validator = lambda n : n > 1 and n <= 26 , ... ) Dual arg: def Foo ( SettingsManager ): settings . data_file = define_option ( default = 4 , validator = lambda file , settings : file_exists ( settings . data_dir + file ), ... ) Important Accessing settings without the dual arg version of the validator might get the wrong value for a setting, before sublasses or the user changes it. validation_error : Error message for an invalid option string : Can be a static string lambda : Can be a lambda or function that returns a string with between 1 and 3 params. val : The value being validated settings : The root settings object in its current state metadata : (As yet undefined) Metadata about where the error occurred and stuff. Note Validation is generally not automatic and needs to be invoked by a subclass of SettingsManager , as we can't expect settings information to be in a valid state at every point in the class definition process.","title":"Validation"},{"location":"api/mixins/settings.html#automatic-derivation","text":"derivation : Lambda or function that will generate the value from other settings information. The parameter is the root settings object. derive_on_read : Bool for whether we should try to derive this value automatically on a read attempt.","title":"Automatic Derivation"},{"location":"api/mixins/settings.html#mandatory-settings","text":"required : Bool for whether the setting must be defined at validation time. Treats an unset value or None as a validation error. (default = False )","title":"Mandatory settings"},{"location":"api/mixins/settings.html#read-only-settings","text":"read_only : Bool for whether the setting should be writable. Read only terms can only be changed by using update_option to set read_only to False first.","title":"Read-Only settings"},{"location":"api/mixins/settings.html#update-functions","text":"update_with : lambda or function with 2 or 3 arguments that intercepts any attempts to set a value directly and allows you to merge or format the values as needed. Arg 1 old : The old value. Will be the default or None if no value is set Arg 2 new : The new value Optional Arg 3 settings : the root settings object you're working with. Note: modifying other settings with this might cause inconsistent results in edge cases.","title":"Update functions"},{"location":"api/mixins/settings.html#copy-function","text":"copy_func : one parameter lambda or function to be used when we're copying a settings object internally. We need to internally deep copy the full settings tree when we're generating each subclass's data.","title":"Copy function"},{"location":"api/mixins/settings.html#aliases","text":"Use define_alias to make two options refer to the same value. def Foo ( SettingsManager ): settings . num_cats = define_alias ( 'animal_counts.cats' ) The input should be relative to the root settings object and either: - A . delineated string like in the example - Or a list like ['animal_counts','cats'] which would be equivalent to the example.","title":"Aliases"},{"location":"api/mixins/settings.html#updating-existing-options","text":"Use update_option to change the properties of a term which already exists. Options are identical to define_option and will overwrite those options. These are separate functions and come with appropriate existence checks.","title":"Updating existing options"},{"location":"api/mixins/settings.html#overloading-and-inheritance","text":"","title":"Overloading and inheritance"},{"location":"api/mixins/settings.html#integrating-validation","text":"Todo Probably we'll have some sort of validate , validate_given , and validate_all functions or something.","title":"Integrating validation"},{"location":"api/mixins/settings.html#error-messages","text":"","title":"Error messages"},{"location":"api/mixins/settings.html#documentation-generation","text":"","title":"Documentation generation"},{"location":"api/mixins/settings.html#option-provenance-tracking","text":"","title":"Option provenance tracking"},{"location":"api/mixins/settings.html#duplication-on-object-init","text":"","title":"Duplication on object init"},{"location":"api/mixins/settings.html#internalimplementation-documentation","text":"","title":"Internal/Implementation Documentation"},{"location":"api/util/dynamic_call.html","text":"Dynamic Call \u00b6 This module contains a dynamic function call interface using inspect.getargspec that allows us to minimise user boilerplate in our EDSL frontend while having a more modular backend. Generated Documentation \u00b6 DynamicCallError \u00b6 Parent error for various things that could go wrong with dynamic_call . Exists to make it easier to provide good error messages to users. __init__ ( self , func , message = '' , ** meta ) special \u00b6 Parameters: Name Type Description Default func function The function we failed to call required message string The error message '' **meta dict Whatever additional metadata is reasonable. {} dynamic_call ( func , arg_dict , order = [], required = []) \u00b6 This function basically attempts to call the input with as much of the available argument options as it'll take. In general the process is as follows: Go through all the standard parameters of the function and match them up with arg_dict entries based on order , using the function defaults if needed. Example For example, if we have: def f ( a , b , c = 34 , d = 72 , e = 14 ): pass order = [ 'a' , 'buzz' , 'bar' , None ] arg_dict = { 'a' : 1 , 'buzz' : 44 , 'bar' : 12 , 'e' : 93 } Then dynamic_call(f,arg_dict,order) would match up each argument in order: a is in the dict, so we can use that, b matches with 'buzz' so we use the value for 'buzz' . c is matches with 'bar' so we ignore the default and use that value. d matches with None , but has a default so that is used. e is after the end of the list (equivalent to order containing None at that position) but there's a matching key in our dict so we use the value from there. Leaving us with a final call of f(1,44,12,72,93) . Match up all the keyword parameters, using the defaults if the values aren't found in arg_dict . If there are more elements in order than there are parameters to the function and there's a variadic positional argument (like *args ), then return those additional parameters. If there are any unused arguments in arg_dict and a variadic keyword argument (like **kwargs ) then add those keyword arguments to the dict. If there are any required arguments that remain unused, then throw an error. Danger I am not at all sure if this is a good idea. Like with prepare_attrs it makes code using it less 'pythonic', but potentially neater and easier for non-python programmers to work with. Unlike prepare_attrs it might be prone to throwing errors to the end user that they're unable to handle. It's dependent on the user of this library to make sure that errors get translated into something more user friendly. Parameters: Name Type Description Default func function The function to call. required arg_dict dict The full dict of possible keyword arguments that the function has available required order list The names for all the basic ordered arguments, None if they're to be matched up by keyword or default. [] required list The names of all the arguments that must be passed to the function [] Returns: Type Description any Whatever func would return, or an error if arguments don't match up. Todo Examples and usage documentation.","title":"DynamicCall"},{"location":"api/util/dynamic_call.html#dynamic-call","text":"This module contains a dynamic function call interface using inspect.getargspec that allows us to minimise user boilerplate in our EDSL frontend while having a more modular backend.","title":"Dynamic Call"},{"location":"api/util/dynamic_call.html#generated-documentation","text":"","title":"Generated Documentation"},{"location":"api/util/dynamic_call.html#exam_gen.util.dynamic_call.DynamicCallError","text":"Parent error for various things that could go wrong with dynamic_call . Exists to make it easier to provide good error messages to users.","title":"DynamicCallError"},{"location":"api/util/dynamic_call.html#exam_gen.util.dynamic_call.DynamicCallError.__init__","text":"Parameters: Name Type Description Default func function The function we failed to call required message string The error message '' **meta dict Whatever additional metadata is reasonable. {}","title":"__init__()"},{"location":"api/util/dynamic_call.html#exam_gen.util.dynamic_call.dynamic_call","text":"This function basically attempts to call the input with as much of the available argument options as it'll take. In general the process is as follows: Go through all the standard parameters of the function and match them up with arg_dict entries based on order , using the function defaults if needed. Example For example, if we have: def f ( a , b , c = 34 , d = 72 , e = 14 ): pass order = [ 'a' , 'buzz' , 'bar' , None ] arg_dict = { 'a' : 1 , 'buzz' : 44 , 'bar' : 12 , 'e' : 93 } Then dynamic_call(f,arg_dict,order) would match up each argument in order: a is in the dict, so we can use that, b matches with 'buzz' so we use the value for 'buzz' . c is matches with 'bar' so we ignore the default and use that value. d matches with None , but has a default so that is used. e is after the end of the list (equivalent to order containing None at that position) but there's a matching key in our dict so we use the value from there. Leaving us with a final call of f(1,44,12,72,93) . Match up all the keyword parameters, using the defaults if the values aren't found in arg_dict . If there are more elements in order than there are parameters to the function and there's a variadic positional argument (like *args ), then return those additional parameters. If there are any unused arguments in arg_dict and a variadic keyword argument (like **kwargs ) then add those keyword arguments to the dict. If there are any required arguments that remain unused, then throw an error. Danger I am not at all sure if this is a good idea. Like with prepare_attrs it makes code using it less 'pythonic', but potentially neater and easier for non-python programmers to work with. Unlike prepare_attrs it might be prone to throwing errors to the end user that they're unable to handle. It's dependent on the user of this library to make sure that errors get translated into something more user friendly. Parameters: Name Type Description Default func function The function to call. required arg_dict dict The full dict of possible keyword arguments that the function has available required order list The names for all the basic ordered arguments, None if they're to be matched up by keyword or default. [] required list The names of all the arguments that must be passed to the function [] Returns: Type Description any Whatever func would return, or an error if arguments don't match up. Todo Examples and usage documentation.","title":"dynamic_call()"}]}; var search = { index: new Promise(resolve => setTimeout(() => resolve(local_index), 0)) }